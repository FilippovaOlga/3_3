{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d499bf6e",
   "metadata": {},
   "source": [
    "# Знакомство со Spark\n",
    "Используем возможности Spark для анализа данных clickstream пользователей новостного Интернет-портала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1595ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb565d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/29 16:40:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local\").\\\n",
    "                    appName(\"Home_work_py\").\\\n",
    "                    config(\"spark.driver.bindAddress\", \"localhost\").\\\n",
    "                    config(\"spark.ui.port\", \"4040\").\\\n",
    "                    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef8756a",
   "metadata": {},
   "source": [
    "### a.       Создайте схему будущего фрейма данных. Схема должна включать следующие атрибуты:\n",
    "-   id -  уникальный идентификатор посетителя сайта. Тип – последовательность чисел фиксированной длины. Данное поле не является первичным ключом.\n",
    "-   timestamp – дата и время события в формате unix timestamp.\n",
    "-   type – тип события, значение из списка (факт посещения(visit), клик по визуальному элементу страницы(click), скролл(scroll), перед на другую страницу(move)).\n",
    "-   page_id – id текущей страницы. Тип - последовательность чисел фиксированной длины.\n",
    "-   tag – каждая страница с новостью размечается редакцией специальными тегами, которые отражают тематику конкретной новости со страницы. Возможный список тематик: политика, спорт, медицина и т.д.\n",
    "-   sign – наличие у пользователя личного кабинета. Значения – True/False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a4a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_web = T.StructType([\n",
    "                T.StructField(\"id\", T.StringType(), True),\n",
    "                T.StructField(\"timestamp\", T.LongType(), True),\n",
    "                T.StructField(\"type\", T.StringType(), True),\n",
    "                T.StructField(\"page_id\", T.IntegerType(), True),\n",
    "                T.StructField(\"tag\", T.StringType(), True),\n",
    "                T.StructField(\"sign\", T.BooleanType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c17df4",
   "metadata": {},
   "source": [
    "### b.       Создайте датафрейм с описанной выше схемой данных.\n",
    "### c.       Наполните датафрейм данными. Пример:\n",
    "(12345, 1667627426, \"click\", 101, \"Sport”, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "510361d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_web =[(1, 1667617426, \"visit\", 101, 'Sport', True),\n",
    "           (1, 1667627486, \"scroll\", 101, 'Sport', True),\n",
    "           (1, 1667637500, \"click\", 101, 'Sport', True),\n",
    "           (1, 1667647505, \"visit\", 102, 'Politics', True),\n",
    "           (1, 1667657565, \"click\", 102, 'Politics', True),\n",
    "           (1, 1667667586, \"visit\", 103, 'Sport', True),\n",
    "           (2, 1667678001, \"visit\", 104, 'Politics', True),\n",
    "           (2, 1667688101, \"scroll\", 104, 'Politics', True),\n",
    "           (2, 1667698151, \"click\", 104, 'Politics', True),\n",
    "           (2, 1667618200, \"visit\", 105, 'Business', True),\n",
    "           (2, 1667628226, \"click\", 105, 'Business', True),\n",
    "           (2, 1667628317, \"visit\", 106, 'Business', True),\n",
    "           (2, 1667638359, \"scroll\", 106, 'Business', True),\n",
    "           (3, 1667638422, \"visit\", 101, 'Sport', False),\n",
    "           (3, 1667648486, \"scroll\", 101, 'Sport', False),\n",
    "           (4, 1667648505, \"visit\", 106, 'Business', False),\n",
    "           (5, 1667658511, \"visit\", 101, 'Sport', True),\n",
    "           (5, 1667658901, \"click\", 101, 'Sport', True),\n",
    "           (5, 1667658926, \"visit\", 102, 'Politics', True),\n",
    "           (5, 1667658976, \"click\", 102, 'Politics', True),\n",
    "           (6, 1667669359, \"scroll\", 106, 'Business', False),\n",
    "           (6, 1667679422, \"visit\", 101, 'Sport', False),\n",
    "           (6, 1667679486, \"scroll\", 101, 'Sport', False),\n",
    "           (6, 1667689505, \"visit\", 106, 'Business', False),\n",
    "           (6, 1667699511, \"visit\", 102, 'Politics', False),\n",
    "           (7, 1667669901, \"click\", 101, 'Sport', True),\n",
    "           (7, 1667659926, \"visit\", 102, 'Politics', True),\n",
    "           (7, 1667649976, \"click\", 102, 'Politics', True)]\n",
    "\n",
    "df_web = spark.createDataFrame(data = data_web, schema = schema_web)\n",
    "\n",
    "# df_web.select(F.from_unixtime('timestamp').alias('ts')).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d76c82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'timestamp', 'type', 'page_id', 'tag', 'sign']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_web.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43a45a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+-------+--------+----+\n",
      "| id| timestamp|  type|page_id|     tag|sign|\n",
      "+---+----------+------+-------+--------+----+\n",
      "|  1|1667617426| visit|    101|   Sport|true|\n",
      "|  1|1667627486|scroll|    101|   Sport|true|\n",
      "|  1|1667637500| click|    101|   Sport|true|\n",
      "|  1|1667647505| visit|    102|Politics|true|\n",
      "|  1|1667657565| click|    102|Politics|true|\n",
      "+---+----------+------+-------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_web.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43da25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_web = df_web.select(*[i for i in df_web.columns if i != \"timestamp\"],\n",
    "                    F.from_unixtime(\"timestamp\").alias(\"event_time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c99ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+--------+----+-------------------+\n",
      "| id|  type|page_id|     tag|sign|         event_time|\n",
      "+---+------+-------+--------+----+-------------------+\n",
      "|  1| visit|    101|   Sport|true|2022-11-05 03:03:46|\n",
      "|  1|scroll|    101|   Sport|true|2022-11-05 05:51:26|\n",
      "|  1| click|    101|   Sport|true|2022-11-05 08:38:20|\n",
      "|  1| visit|    102|Politics|true|2022-11-05 11:25:05|\n",
      "|  1| click|    102|Politics|true|2022-11-05 14:12:45|\n",
      "+---+------+-------+--------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_web.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b7bc2",
   "metadata": {},
   "source": [
    "### d.       Решите следующие задачи:\n",
    "\n",
    "-   Вывести топ-5 самых активных посетителей сайта\n",
    "-   Посчитать процент посетителей, у которых есть ЛК\n",
    "-   Вывести топ-5 страниц сайта по показателю общего кол-ва кликов на данной странице\n",
    "-   Добавьте столбец к фрейму данных со значением временного диапазона в рамках суток с размером окна – 4 часа(0-4, 4-8, 8-12 и т.д.)\n",
    "-   Выведите временной промежуток на основе предыдущего задания, в течение которого было больше всего активностей на сайте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd740a29",
   "metadata": {},
   "source": [
    "##### топ-5 самых активных посетителей сайта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "439a1cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:==================================>                    (125 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|activity|\n",
      "+---+--------+\n",
      "|  2|       7|\n",
      "|  1|       6|\n",
      "|  6|       5|\n",
      "|  5|       4|\n",
      "|  7|       3|\n",
      "+---+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_web.groupby(\"id\")\\\n",
    "    .agg(F.count(\"*\").alias(\"activity\"))\\\n",
    "    .orderBy(\"activity\", ascending = False)\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f8199",
   "metadata": {},
   "source": [
    "##### Посчитать процент посетителей, у которых есть ЛК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42350024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля пользователей с лк: 57.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "r_lk = df_web.filter(\"sign = true\").select(\"id\").distinct().count()\n",
    "r_tot = df_web.select(\"id\").distinct().count()\n",
    "print(\"Доля пользователей с лк: {0}%\".format(round(r_lk/r_tot*100,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbed0256",
   "metadata": {},
   "source": [
    "##### Вывести топ-5 страниц сайта по показателю общего кол-ва кликов на данной странице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d44e7c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|page_id|count|\n",
      "+-------+-----+\n",
      "|    101|    3|\n",
      "|    102|    3|\n",
      "|    105|    1|\n",
      "|    104|    1|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_web.filter('type = \"click\"')\\\n",
    "    .groupby(\"page_id\")\\\n",
    "    .count()\\\n",
    "    .orderBy(\"count\", ascending = False)\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36281ae",
   "metadata": {},
   "source": [
    "##### Добавьте столбец к фрейму данных со значением временного диапазона в рамках суток с размером окна – 4 часа(0-4, 4-8, 8-12 и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7ca460d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+--------+-----+-------------------+------+\n",
      "| id|  type|page_id|     tag| sign|         event_time|period|\n",
      "+---+------+-------+--------+-----+-------------------+------+\n",
      "|  1| visit|    101|   Sport| true|2022-11-05 03:03:46|     0|\n",
      "|  1|scroll|    101|   Sport| true|2022-11-05 05:51:26|     1|\n",
      "|  1| click|    101|   Sport| true|2022-11-05 08:38:20|     2|\n",
      "|  1| visit|    102|Politics| true|2022-11-05 11:25:05|     2|\n",
      "|  1| click|    102|Politics| true|2022-11-05 14:12:45|     3|\n",
      "|  1| visit|    103|   Sport| true|2022-11-05 16:59:46|     4|\n",
      "|  2| visit|    104|Politics| true|2022-11-05 19:53:21|     4|\n",
      "|  2|scroll|    104|Politics| true|2022-11-05 22:41:41|     5|\n",
      "|  2| click|    104|Politics| true|2022-11-06 01:29:11|     0|\n",
      "|  2| visit|    105|Business| true|2022-11-05 03:16:40|     0|\n",
      "|  2| click|    105|Business| true|2022-11-05 06:03:46|     1|\n",
      "|  2| visit|    106|Business| true|2022-11-05 06:05:17|     1|\n",
      "|  2|scroll|    106|Business| true|2022-11-05 08:52:39|     2|\n",
      "|  3| visit|    101|   Sport|false|2022-11-05 08:53:42|     2|\n",
      "|  3|scroll|    101|   Sport|false|2022-11-05 11:41:26|     2|\n",
      "|  4| visit|    106|Business|false|2022-11-05 11:41:45|     2|\n",
      "|  5| visit|    101|   Sport| true|2022-11-05 14:28:31|     3|\n",
      "|  5| click|    101|   Sport| true|2022-11-05 14:35:01|     3|\n",
      "|  5| visit|    102|Politics| true|2022-11-05 14:35:26|     3|\n",
      "|  5| click|    102|Politics| true|2022-11-05 14:36:16|     3|\n",
      "|  6|scroll|    106|Business|false|2022-11-05 17:29:19|     4|\n",
      "|  6| visit|    101|   Sport|false|2022-11-05 20:17:02|     5|\n",
      "|  6|scroll|    101|   Sport|false|2022-11-05 20:18:06|     5|\n",
      "|  6| visit|    106|Business|false|2022-11-05 23:05:05|     5|\n",
      "|  6| visit|    102|Politics|false|2022-11-06 01:51:51|     0|\n",
      "|  7| click|    101|   Sport| true|2022-11-05 17:38:21|     4|\n",
      "|  7| visit|    102|Politics| true|2022-11-05 14:52:06|     3|\n",
      "|  7| click|    102|Politics| true|2022-11-05 12:06:16|     3|\n",
      "+---+------+-------+--------+-----+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_web.withColumn(\"period\", F.floor(F.hour(\"event_time\") / F.lit(4))).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f24391",
   "metadata": {},
   "source": [
    "##### Выведите временной промежуток на основе предыдущего задания, в течение которого было больше всего активностей на сайте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bad4de92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|period|\n",
      "+------+\n",
      "|     3|\n",
      "+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df_web.withColumn(\"period\", F.floor(F.hour(\"event_time\") / F.lit(4)))\\\n",
    ".groupby(\"period\").count().orderBy(\"count\", ascending = False).select(\"period\").show(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477096f4",
   "metadata": {},
   "source": [
    "- Создайте второй фрейм данных, который будет содержать информацию о ЛК посетителя сайта со следующим списком атрибутов\n",
    "\n",
    "    1. Id – уникальный идентификатор личного кабинета\n",
    "    2. User_id – уникальный идентификатор посетителя\n",
    "    3. ФИО посетителя\n",
    "    4. Дату рождения посетителя \n",
    "    5. Дата создания ЛК\n",
    "\n",
    "-   Вывести фамилии посетителей, которые читали хотя бы одну новость про спорт.\n",
    "-   Выведите 10% ЛК, у которых максимальная разница между датой создания ЛК и датой последнего посещения.\n",
    "-   Вывести топ-5 страниц, которые чаще всего посещают мужчины и топ-5 страниц, которые посещают чаще женщины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7d9bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_lk = T.StructType([\n",
    "                T.StructField(\"id\", T.StringType(), True),\n",
    "                T.StructField(\"user_id\", T.IntegerType(), True),\n",
    "                T.StructField(\"fio\", T.StringType(), True),\n",
    "                T.StructField(\"dob\", T.DateType(), True),\n",
    "                T.StructField(\"doc\", T.DateType(), True)])\n",
    "\n",
    "data_lk = [\n",
    "    (101, 2, \"Иванов Иван Иванович\", datetime.datetime(1990, 7, 5), datetime.datetime(2016, 8, 1)),\n",
    "    (102, 5, \"Александрова Александра Александровна\", datetime.datetime(1995, 1, 22), datetime.datetime(2017, 10, 7)),\n",
    "    (103, 1, \"Тарасова Алина Владимировна\", datetime.datetime(1975, 8, 12), datetime.datetime(2018, 10, 7)),\n",
    "    (104, 6, \"Иванов Владимир Олегович\", datetime.datetime(1980, 4, 15), datetime.datetime(2019, 7, 15))\n",
    "]\n",
    "\n",
    "df_lk = spark.createDataFrame(data = data_lk, schema = schema_lk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c9c84fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+----------+----------+---+------+-------+--------+-----+-------------------+\n",
      "| id|user_id|                 fio|       dob|       doc| id|  type|page_id|     tag| sign|         event_time|\n",
      "+---+-------+--------------------+----------+----------+---+------+-------+--------+-----+-------------------+\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1| visit|    101|   Sport| true|2022-11-05 03:03:46|\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1|scroll|    101|   Sport| true|2022-11-05 05:51:26|\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1| click|    101|   Sport| true|2022-11-05 08:38:20|\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1| visit|    102|Politics| true|2022-11-05 11:25:05|\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1| click|    102|Politics| true|2022-11-05 14:12:45|\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1| visit|    103|   Sport| true|2022-11-05 16:59:46|\n",
      "|104|      6|Иванов Владимир О...|1980-04-15|2019-07-15|  6|scroll|    106|Business|false|2022-11-05 17:29:19|\n",
      "|104|      6|Иванов Владимир О...|1980-04-15|2019-07-15|  6| visit|    101|   Sport|false|2022-11-05 20:17:02|\n",
      "|104|      6|Иванов Владимир О...|1980-04-15|2019-07-15|  6|scroll|    101|   Sport|false|2022-11-05 20:18:06|\n",
      "|104|      6|Иванов Владимир О...|1980-04-15|2019-07-15|  6| visit|    106|Business|false|2022-11-05 23:05:05|\n",
      "+---+-------+--------------------+----------+----------+---+------+-------+--------+-----+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all = df_lk.alias(\"lk\").join(df_web.alias(\"web\"),\n",
    "                                    on = [F.col(\"lk.user_id\") == F.col(\"web.id\")],\n",
    "                                    how = \"left\")\n",
    "df_all.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622245d",
   "metadata": {},
   "source": [
    "##### Вывести фамилии посетителей, которые читали хотя бы одну новость про спорт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e91a0760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|      Family|\n",
      "+------------+\n",
      "|      Иванов|\n",
      "|    Тарасова|\n",
      "|Александрова|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.filter('tag = \"Sport\" AND ( type = \"scroll\" OR type = \"visit\")') \\\n",
    "    .select(F.split(df_all.fio,' ')[0].alias(\"Family\")) \\\n",
    "    .distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e1e5da",
   "metadata": {},
   "source": [
    "##### Выведите 10% ЛК, у которых максимальная разница между датой создания ЛК и датой последнего посещения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed37bcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:============================================>         (165 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|Diff_in_years|\n",
      "+---+-------------+\n",
      "|101|          6.3|\n",
      "+---+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_all.groupby('lk.id')\\\n",
    "    .agg(F.max(F.round(F.datediff(\"event_time\", \"doc\")/365,1)).alias('Diff_in_years'))\\\n",
    "    .orderBy(\"Diff_in_years\",ascending = False)\\\n",
    "    .show(max(1,round(df_lk.select(\"id\").distinct().count()*0.1,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d310fee4",
   "metadata": {},
   "source": [
    "##### Вывести топ-5 страниц, которые чаще всего посещают мужчины и топ-5 страниц, которые посещают чаще женщины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e4d61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(T.StringType())\n",
    "def calc_gender(fio):\n",
    "    surname, name, middlename = fio.split(' ')\n",
    "    if (((surname[-2:] == \"ов\") or (surname[-2:] == \"ев\")) and \\\n",
    "        middlename[-2:] == \"ич\"):\n",
    "        return 'm'\n",
    "    else:\n",
    "        return 'w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "847d407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+------+\n",
      "|page_id|gender|count|rating|\n",
      "+-------+------+-----+------+\n",
      "|    106|     m|    4|     1|\n",
      "|    104|     m|    3|     2|\n",
      "|    105|     m|    2|     3|\n",
      "|    101|     m|    2|     4|\n",
      "|    102|     m|    1|     5|\n",
      "|    101|     w|    5|     1|\n",
      "|    102|     w|    4|     2|\n",
      "|    103|     w|    1|     3|\n",
      "+-------+------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all.withColumn(\"gender\", calc_gender(F.col(\"fio\"))) \\\n",
    "      .select(\"page_id\", \"gender\") \\\n",
    "      .groupby(\"page_id\", \"gender\") \\\n",
    "      .count() \\\n",
    "      .withColumn(\"rating\", F.row_number()\\\n",
    "                                    .over(Window.partitionBy(\"gender\").orderBy(F.col(\"count\").desc())))\\\n",
    "      .filter(\"rating < 6\")\\\n",
    "      .show(10)\n",
    "#      .select(\"page_id\",\"gender\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d729c9",
   "metadata": {},
   "source": [
    "### e.       Создайте в Postgres таблицы аналогичной структуры и выполните следующие задания с помощью Spark.\n",
    "\n",
    "-    Создайте витрину данных в Postgres со следующим содержанием\n",
    "\n",
    "    1.       Id посетителя\n",
    "    2.       Возраст посетителя\n",
    "    3.       Пол посетителя (постарайтесь описать логику вычисления пола в отдельной пользовательской функции)\n",
    "    4.       Любимая тематика новостей\n",
    "    5.       Любимый временной диапазон посещений\n",
    "    6.       Id личного кабинета\n",
    "    7.       Разница в днях между созданием ЛК и датой последнего посещения. (-1 если ЛК нет)\n",
    "    8.       Общее кол-во посещений сайта\n",
    "    9.       Средняя длина сессии(сессией считаем временной промежуток, который охватывает последовательность событий, которые происходили подряд с разницей не более 5 минут).\n",
    "    10.   Среднее кол-во активностей в рамках одной сессии\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad47faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 95:=============================================>         (82 + 2) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+----------+----------+---+------+-------+--------+----+-------------------+------+\n",
      "| id|user_id|                 fio|       dob|       doc| id|  type|page_id|     tag|sign|         event_time|gender|\n",
      "+---+-------+--------------------+----------+----------+---+------+-------+--------+----+-------------------+------+\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1| visit|    101|   Sport|true|2022-11-05 03:03:46|     w|\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1|scroll|    101|   Sport|true|2022-11-05 05:51:26|     w|\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1| click|    101|   Sport|true|2022-11-05 08:38:20|     w|\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1| visit|    102|Politics|true|2022-11-05 11:25:05|     w|\n",
      "|103|      1|Тарасова Алина Вл...|1975-08-12|2018-10-07|  1| click|    102|Politics|true|2022-11-05 14:12:45|     w|\n",
      "+---+-------+--------------------+----------+----------+---+------+-------+--------+----+-------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_all_g = df_all.withColumn(\"gender\", calc_gender(F.col(\"fio\")))\n",
    "df_all_g.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "137da453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tag = df_all_g.groupby(\"user_id\", \"tag\").count()\\\n",
    "    .withColumn(\"rating\",F.row_number().over(Window.partitionBy(\"user_id\").orderBy(F.col(\"count\").desc())))\\\n",
    "    .filter(\"rating=1\").select(\"user_id\",\"tag\")\n",
    "df_period = df_all_g.withColumn(\"period\", F.floor(F.hour(\"event_time\") / F.lit(4)))\\\n",
    "    .groupby(\"user_id\", \"period\").count()\\\n",
    "    .withColumn(\"rating\",F.row_number().over(Window.partitionBy(\"user_id\").orderBy(F.col(\"count\").desc())))\\\n",
    "    .filter(\"rating=1\").select(\"user_id\",\"period\")\n",
    "df_period = df_all_g.withColumn(\"period\", F.floor(F.hour(\"event_time\") / F.lit(4)))\\\n",
    "    .groupby(\"user_id\", \"period\").count()\\\n",
    "    .withColumn(\"rating\",F.row_number().over(Window.partitionBy(\"user_id\").orderBy(F.col(\"count\").desc())))\\\n",
    "    .filter(\"rating=1\").select(\"user_id\",\"period\")\n",
    "df_diff = df_all.groupby('user_id')\\\n",
    "    .agg(F.max(F.round(F.datediff(\"event_time\", \"doc\"),0)).alias('diff'))\\\n",
    "    .orderBy(\"diff\",ascending = False)\n",
    "df_visits = df_all.filter('type = \"visit\"')\\\n",
    "    .groupby('user_id')\\\n",
    "    .agg(F.count(F.col(\"user_id\")).alias(\"visits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cca4e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----+------+\n",
      "|user_id|         event_time|n_ses|n_ses2|\n",
      "+-------+-------------------+-----+------+\n",
      "|      1|2022-11-05 03:03:46|    1|     1|\n",
      "|      1|2022-11-05 05:51:26|    2|     2|\n",
      "|      1|2022-11-05 08:38:20|    3|     3|\n",
      "|      1|2022-11-05 11:25:05|    4|     4|\n",
      "|      1|2022-11-05 14:12:45|    5|     5|\n",
      "|      1|2022-11-05 16:59:46|    6|     6|\n",
      "|      6|2022-11-05 17:29:19|    1|     1|\n",
      "|      6|2022-11-05 20:17:02|    2|     2|\n",
      "|      6|2022-11-05 20:18:06| null|     2|\n",
      "|      6|2022-11-05 23:05:05|    3|     3|\n",
      "|      6|2022-11-06 01:51:51|    4|     4|\n",
      "|      5|2022-11-05 14:28:31|    1|     1|\n",
      "|      5|2022-11-05 14:35:01|    2|     2|\n",
      "|      5|2022-11-05 14:35:26| null|     2|\n",
      "|      5|2022-11-05 14:36:16| null|     2|\n",
      "|      2|2022-11-05 03:16:40|    1|     1|\n",
      "|      2|2022-11-05 06:03:46|    2|     2|\n",
      "|      2|2022-11-05 06:05:17| null|     2|\n",
      "|      2|2022-11-05 08:52:39|    3|     3|\n",
      "|      2|2022-11-05 19:53:21|    4|     4|\n",
      "+-------+-------------------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ses = df_all\\\n",
    "    .withColumn(\"Pred_T\",F.lag(\"event_time\").over(Window.partitionBy(\"user_id\").orderBy(F.col(\"event_time\"))))\\\n",
    "    .withColumn(\"dt\",F.coalesce(F.round((F.unix_timestamp(\"event_time\")-F.unix_timestamp(\"Pred_T\"))/60.,2),F.lit(-1)).alias('dt'))\\\n",
    "    .select(\"user_id\",\"event_time\",\"dt\").orderBy(\"user_id\",\"event_time\")\\\n",
    "    .withColumn(\"new_ses\", F.when(F.col(\"dt\") >= \"5\",\"2\")\n",
    "                                 .when(F.col(\"dt\") == \"-1\",\"1\")\n",
    "                                 .otherwise(\"Cont\"))\\\n",
    "    .filter(\"new_ses = 1 OR new_ses = 2\")\\\n",
    "    .withColumn(\"n_ses\",F.row_number().over(Window.partitionBy(\"user_id\").orderBy(\"event_time\")))\\\n",
    "    .select(\"user_id\",\"event_time\",\"n_ses\").alias(\"ses\")\n",
    "df_ses = df_all.select(\"user_id\",\"event_time\").alias(\"df\").join(df_ses.alias(\"ses\"),\n",
    "                                    on = [F.col(\"ses.user_id\") == F.col(\"df.user_id\"),\n",
    "                                         F.col(\"ses.event_time\") == F.col(\"df.event_time\")],\n",
    "                                    how = \"left\")\\\n",
    "    .orderBy(\"df.user_id\",\"df.event_time\")\\\n",
    "    .select(\"df.user_id\",\"df.event_time\",\"n_ses\")\n",
    "\n",
    "df_ses=df_ses.withColumn(\"n_ses2\",F.max(\"n_ses\").over(Window.partitionBy(\"user_id\").orderBy(\"event_time\")))\n",
    "df_ses.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10b9df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|user_id|      avg_ses_time|       avg_ses_act|\n",
      "+-------+------------------+------------------+\n",
      "|      1|               0.0|               1.0|\n",
      "|      6|              16.0|              1.25|\n",
      "|      5|              37.5|               2.0|\n",
      "|      2|15.166666666666666|1.1666666666666667|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_ses = df_ses.groupby(\"user_id\",\"n_ses2\")\\\n",
    "    .agg((F.max(F.unix_timestamp(\"event_time\"))-F.min(F.unix_timestamp(\"event_time\"))).alias(\"Ses_Time\"),\n",
    "         F.count(\"event_time\").alias(\"Ses_Act\"))\\\n",
    "    .groupby(\"user_id\").agg(F.avg(\"Ses_Time\").alias(\"avg_ses_time\"),F.avg(\"Ses_Act\").alias(\"avg_ses_act\"))\n",
    "df_ses.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb71dde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 307:============================================>          (61 + 1) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+---+-------+--------+-------+------+-------+----+-------+------+-------+------------------+------------------+\n",
      "|user_id| age|gender| id|user_id|     tag|user_id|period|user_id|diff|user_id|visits|user_id|      avg_ses_time|       avg_ses_act|\n",
      "+-------+----+------+---+-------+--------+-------+------+-------+----+-------+------+-------+------------------+------------------+\n",
      "|      1|47.0|     w|103|      1|   Sport|      1|     2|      1|1490|      1|     3|      1|               0.0|               1.0|\n",
      "|      6|43.0|     m|104|      6|Business|      6|     5|      6|1210|      6|     3|      6|              16.0|              1.25|\n",
      "|      5|28.0|     w|102|      5|   Sport|      5|     3|      5|1855|      5|     2|      5|              37.5|               2.0|\n",
      "|      2|32.0|     m|101|      2|Business|      2|     0|      2|2288|      2|     3|      2|15.166666666666666|1.1666666666666667|\n",
      "+-------+----+------+---+-------+--------+-------+------+-------+----+-------+------+-------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1 = df_all_g.withColumn(\"age\",F.round(F.datediff(F.current_date(), \"dob\")/365,0)).select(\"user_id\",\"age\",\"gender\",\"lk.id\").distinct().alias(\"df0\")\n",
    "df1 = df1.join(df_tag.alias(\"tg\"),\n",
    "                           on = [F.col(\"tg.user_id\") == F.col(\"df0.user_id\")],\n",
    "                           how = \"left\")\n",
    "df1 = df1.join(df_period.alias(\"pr\"),\n",
    "                           on = [F.col(\"pr.user_id\") == F.col(\"df0.user_id\")],\n",
    "                           how = \"left\")\n",
    "df1 = df1.join(df_diff.alias(\"df\"),\n",
    "                           on = [F.col(\"df.user_id\") == F.col(\"df0.user_id\")],\n",
    "                           how = \"left\")\n",
    "df1 = df1.join(df_visits.alias(\"vs\"),\n",
    "                           on = [F.col(\"vs.user_id\") == F.col(\"df0.user_id\")],\n",
    "                           how = \"left\")\n",
    "df1 = df1.join(df_ses.alias(\"ses\"),\n",
    "                           on = [F.col(\"ses.user_id\") == F.col(\"df0.user_id\")],\n",
    "                           how = \"left\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d153f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 397:====================================================>  (71 + 1) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+--------+------+---+----+------+------------------+------------------+\n",
      "|user_id| age|gender|     tag|period| id|diff|visits|      avg_ses_time|       avg_ses_act|\n",
      "+-------+----+------+--------+------+---+----+------+------------------+------------------+\n",
      "|      1|47.0|     w|   Sport|     2|103|1490|     3|               0.0|               1.0|\n",
      "|      6|43.0|     m|Business|     5|104|1210|     3|              16.0|              1.25|\n",
      "|      5|28.0|     w|   Sport|     3|102|1855|     2|              37.5|               2.0|\n",
      "|      2|32.0|     m|Business|     0|101|2288|     3|15.166666666666666|1.1666666666666667|\n",
      "+-------+----+------+--------+------+---+----+------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1=df1.select(\"df0.user_id\",\"age\",\"gender\",\"tag\",\"period\",\"df0.id\",\"diff\",\"visits\",\"avg_ses_time\",\"avg_ses_act\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34556d7b",
   "metadata": {},
   "source": [
    "d1 = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432\") \\\n",
    "    .option(\"dbtable\", \"users_stat\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .load()\n",
    "# подключиться к postgres так и не получилось.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d98b0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### f.        Редакция совместно с аналитиками хотят провести масштабную рекламную кампанию, в рамках которой на сайте будут выпущены 3 новости с новой тематикой. Рекламный бюджет позволяет охватить только 10% доступной вам аудитории посетителей сайта. Напишите запрос, который позволит вычислить целевую аудиторию для данных новостей. Постарайтесь объяснить ваше решение.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c48bc060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|user_id|tags|\n",
      "+-------+----+\n",
      "|      1|   2|\n",
      "|      6|   3|\n",
      "|      5|   2|\n",
      "|      2|   2|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# нужно дополнить данные насколько разнообразны интересы у пользователей - чем больше тематик просматривают, тем вероятнее, что новую посмотрят\n",
    "df_tags = df_all.select(\"user_id\",\"tag\").distinct()\\\n",
    "    .groupby(\"user_id\").agg(F.count(\"user_id\").alias(\"tags\"))\n",
    "df_tags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f735faae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 437:===================================================> (193 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------------------+------------------+\n",
      "|user_id|tags|       avg_ses_act|      avg_ses_time|\n",
      "+-------+----+------------------+------------------+\n",
      "|      6|   3|              1.25|              16.0|\n",
      "|      5|   2|               2.0|              37.5|\n",
      "|      2|   2|1.1666666666666667|15.166666666666666|\n",
      "|      1|   2|               1.0|               0.0|\n",
      "+-------+----+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2 = df1.alias(\"df\")\\\n",
    "    .join(df_tags.alias(\"tgs\"),\n",
    "                 on = [F.col(\"tgs.user_id\") == F.col(\"df.user_id\")],\n",
    "                 how = \"left\")\\\n",
    "    .orderBy(F.col(\"tags\").desc(),\n",
    "             F.col(\"avg_ses_act\").desc(),\n",
    "             F.col(\"avg_ses_time\").desc())\\\n",
    "    .select(\"df.user_id\",\"tags\",\"avg_ses_act\",\"avg_ses_time\")\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9725454f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 488:==================================================>  (189 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----------+------------+\n",
      "|user_id|tags|avg_ses_act|avg_ses_time|\n",
      "+-------+----+-----------+------------+\n",
      "|      6|   3|       1.25|        16.0|\n",
      "+-------+----+-----------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.show(max(1,round(df2.select(\"user_id\").distinct().count()*0.1,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5e87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e32d180",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o574.load.\n: java.sql.SQLException: No suitable driver\n\tat java.sql.DriverManager.getDriver(DriverManager.java:315)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:105)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:105)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:35)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:32)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:339)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:279)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:268)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:268)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:203)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjdbc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjdbc:postgresql://localhost:5432\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdbtable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpublic.users_stat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgres\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgres\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/readwriter.py:184\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoSeq(path)))\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py:131\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    133\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o574.load.\n: java.sql.SQLException: No suitable driver\n\tat java.sql.DriverManager.getDriver(DriverManager.java:315)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:105)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:105)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:35)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:32)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:339)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:279)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:268)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:268)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:203)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "d1 = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432\") \\\n",
    "    .option(\"dbtable\", \"public.users_stat\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"postgres\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c4de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
